{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIOXoY1xgiww"
      },
      "source": [
        "# Train a miniGPT language model with JAX\n",
        "\n",
        "This tutorial demonstrates how to use JAX, [Flax NNX](http://flax.readthedocs.io) and [Optax](http://optax.readthedocs.io) for language model (pre)training on GPU. It was originally inspired by the [Keras miniGPT tutorial](https://keras.io/examples/generative/text_generation_with_miniature_gpt/).\n",
        "\n",
        "If you are new to JAX for AI, check out the [introductory tutorial](https://jax-ai-stack.readthedocs.io/en/latest/getting_started_with_jax_for_AI.html), which covers neural network building with [Flax NNX](https://flax.readthedocs.io/en/latest/nnx_basics.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTmz5Cbco7n_"
      },
      "source": [
        "## Setup\n",
        "\n",
        "JAX installation is covered in [this guide](https://jax.readthedocs.io/en/latest/installation.html) on the JAX documentation site. We will use [Tiktoken](https://github.com/openai/tiktoken) for tokenization and [Grain](https://google-grain.readthedocs.io/en/latest/index.html) for data loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMsOIc7ouCO",
        "outputId": "30d01d15-ceb6-42ed-eedf-6d10d780e5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq tiktoken grain matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcji_799n4eA"
      },
      "source": [
        "Check the available JAX devices, or [`jax.Device`](https://jax.readthedocs.io/en/latest/_autosummary/jax.Device.html), with [`jax.devices()`](https://jax.readthedocs.io/en/latest/_autosummary/jax.devices.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS9sQEY3n0mB"
      },
      "outputs": [],
      "source": [
        "import jax, os\n",
        "jax.devices()\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHzJ_bokoovZ"
      },
      "source": [
        "Get the [TinyStories dataset from Hugging Face](https://huggingface.co/datasets/roneneldan/TinyStories). We only use the training split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUjQsgQEmI1N",
        "outputId": "e77ba705-cef8-4118-bf6c-b8189656835b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-07 08:51:49--  https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-valid.txt?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.112.45, 3.167.112.38, 3.167.112.25, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.112.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/42/7f/427f7497b6c6596c18b46d5a72e61364fcad12aa433c60a0dbd4d344477b9d81/94e431816c4cce81ff71e4408ff8d3bda9a42e8d2663986697c3954288cb38b4?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27TinyStories-valid.txt%3B+filename%3D%22TinyStories-valid.txt%22%3B&response-content-type=text%2Fplain&Expires=1751881909&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTg4MTkwOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Mi83Zi80MjdmNzQ5N2I2YzY1OTZjMThiNDZkNWE3MmU2MTM2NGZjYWQxMmFhNDMzYzYwYTBkYmQ0ZDM0NDQ3N2I5ZDgxLzk0ZTQzMTgxNmM0Y2NlODFmZjcxZTQ0MDhmZjhkM2JkYTlhNDJlOGQyNjYzOTg2Njk3YzM5NTQyODhjYjM4YjQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=nfu0FajHeJY4NDjlDDFtkb5t9lLv8vo6sRXH3M77uZ4wLGZMMgCZIiI0RcbOLWxiwLB9BDYL1Y5tqWkPR6L36MMnG9CrcTXlIA7MhvkluKHzwwVbFNXmhIRhH7-4TXe%7EDDNauzL0dQlx1SUXko4uUSC3RbV3rij5judt0vvuNoY-2qkUyaNxyEFUAQ1gpXmdhPG1giu9xRJVgEsT9vQDg1iG96A9Swlwk9Ck98fcwT2xTqrutYXq-EnXAQbA182Xk8MbaTTRfiyROVO7zjwiIwyx15Tj0O4ZGKU05oCljml516iMv6%7Ejmmrd5KiMxx6yDkvb7Fxhp4W1IMzQjLEqKQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-07-07 08:51:49--  https://cdn-lfs.hf.co/repos/42/7f/427f7497b6c6596c18b46d5a72e61364fcad12aa433c60a0dbd4d344477b9d81/94e431816c4cce81ff71e4408ff8d3bda9a42e8d2663986697c3954288cb38b4?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27TinyStories-valid.txt%3B+filename%3D%22TinyStories-valid.txt%22%3B&response-content-type=text%2Fplain&Expires=1751881909&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTg4MTkwOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Mi83Zi80MjdmNzQ5N2I2YzY1OTZjMThiNDZkNWE3MmU2MTM2NGZjYWQxMmFhNDMzYzYwYTBkYmQ0ZDM0NDQ3N2I5ZDgxLzk0ZTQzMTgxNmM0Y2NlODFmZjcxZTQ0MDhmZjhkM2JkYTlhNDJlOGQyNjYzOTg2Njk3YzM5NTQyODhjYjM4YjQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=nfu0FajHeJY4NDjlDDFtkb5t9lLv8vo6sRXH3M77uZ4wLGZMMgCZIiI0RcbOLWxiwLB9BDYL1Y5tqWkPR6L36MMnG9CrcTXlIA7MhvkluKHzwwVbFNXmhIRhH7-4TXe%7EDDNauzL0dQlx1SUXko4uUSC3RbV3rij5judt0vvuNoY-2qkUyaNxyEFUAQ1gpXmdhPG1giu9xRJVgEsT9vQDg1iG96A9Swlwk9Ck98fcwT2xTqrutYXq-EnXAQbA182Xk8MbaTTRfiyROVO7zjwiIwyx15Tj0O4ZGKU05oCljml516iMv6%7Ejmmrd5KiMxx6yDkvb7Fxhp4W1IMzQjLEqKQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.171.61.75, 3.171.61.127, 3.171.61.18, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.171.61.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19447282 (19M) [text/plain]\n",
            "Saving to: ‘TinyStories-train.txt’\n",
            "\n",
            "\rTinyStories-train.t   0%[                    ]       0  --.-KB/s               \rTinyStories-train.t 100%[===================>]  18.55M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-07 08:51:49 (321 MB/s) - ‘TinyStories-train.txt’ saved [19447282/19447282]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-valid.txt?download=true -O TinyStories-train.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKE2uUafLobI"
      },
      "source": [
        "Import the necessary modules, including JAX NumPy, Flax NNX, Optax, Grain, pandas, and Tiktoken:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKYFNOhdLq98"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax.nnx as nnx\n",
        "import optax\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import grain.python as pygrain\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyt7MV6prz1"
      },
      "source": [
        "## Define the miniGPT model with Flax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZKdhNo98NgG"
      },
      "source": [
        "We will use the GPT-2 tokenizer from the [Tiktoken](https://github.com/openai/tiktoken) library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWbkk1V7-Isg"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define the model."
      ],
      "metadata": {
        "id": "OfR1dX3qA7_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0p-IHurrB9i"
      },
      "outputs": [],
      "source": [
        "# Define a triangular mask for causal attention with `jax.numpy.tril` and `jax.numpy.ones`.\n",
        "def causal_attention_mask(seq_len):\n",
        "    return jnp.tril(jnp.ones((seq_len, seq_len)))\n",
        "\n",
        "class TransformerBlock(nnx.Module):\n",
        "    \"\"\" A single Transformer block.\n",
        "\n",
        "    Each Transformer block processes input sequences via self-attention and feed-forward networks.\n",
        "\n",
        "    Args:\n",
        "        embed_dim (int): Embedding dimensionality.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        ff_dim (int): Dimensionality of the feed-forward network.\n",
        "        rngs (flax.nnx.Rngs): A Flax NNX stream of JAX PRNG keys.\n",
        "        rate (float): Dropout rate. Defaults to 0.1.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, *, rngs: nnx.Rngs, rate: float = 0.1):\n",
        "        # Multi-Head Attention (MHA) with `flax.nnx.MultiHeadAttention`.\n",
        "        self.mha = nnx.MultiHeadAttention(num_heads=num_heads,\n",
        "                                          in_features=embed_dim,\n",
        "                                          rngs=rngs)\n",
        "        # The first dropout with `flax.nnx.Dropout`.\n",
        "        self.dropout1 = nnx.Dropout(rate=rate)\n",
        "        # First layer normalization with `flax.nnx.LayerNorm`.\n",
        "        self.layer_norm1 = nnx.LayerNorm(epsilon=1e-6,\n",
        "                                         num_features=embed_dim,\n",
        "                                         rngs=rngs)\n",
        "        # The first linear transformation for the feed-forward network with `flax.nnx.Linear`.\n",
        "        self.linear1 = nnx.Linear(in_features=embed_dim,\n",
        "                                  out_features=ff_dim,\n",
        "                                  rngs=rngs)\n",
        "        # The second linear transformation for the feed-forward network with `flax.nnx.Linear`.\n",
        "        self.linear2 = nnx.Linear(in_features=ff_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  rngs=rngs)\n",
        "        # The second dropout with `flax.nnx.Dropout`.\n",
        "        self.dropout2 = nnx.Dropout(rate=rate)\n",
        "        # Second layer normalization with `flax.nnx.LayerNorm`.\n",
        "        self.layer_norm2 = nnx.LayerNorm(epsilon=1e-6,\n",
        "                                         num_features=embed_dim,\n",
        "                                         rngs=rngs)\n",
        "\n",
        "\n",
        "    # Apply the Transformer block to the input sequence.\n",
        "    def __call__(self, inputs, training: bool = False):\n",
        "        input_shape = inputs.shape\n",
        "        _, seq_len, _ = input_shape\n",
        "\n",
        "        # Instantiate the causal attention mask.\n",
        "        mask = causal_attention_mask(seq_len)\n",
        "\n",
        "        # Apply Multi-Head Attention with the causal attention mask.\n",
        "        attention_output = self.mha(\n",
        "            inputs_q=inputs,\n",
        "            mask=mask,\n",
        "            decode=False\n",
        "        )\n",
        "        # Apply the first dropout.\n",
        "        attention_output = self.dropout1(attention_output, deterministic=not training)\n",
        "        # Apply the first layer normalization.\n",
        "        out1 = self.layer_norm1(inputs + attention_output)\n",
        "\n",
        "        # The feed-forward network.\n",
        "        # Apply the first linear transformation.\n",
        "        ffn_output = self.linear1(out1)\n",
        "        # Apply the ReLU activation with `flax.nnx.relu`.\n",
        "        ffn_output = nnx.relu(ffn_output)\n",
        "        # Apply the second linear transformation.\n",
        "        ffn_output = self.linear2(ffn_output)\n",
        "        # Apply the second dropout.\n",
        "        ffn_output = self.dropout2(ffn_output, deterministic=not training)\n",
        "        # Apply the second layer normalization and return the output of the Transformer block.\n",
        "        return self.layer_norm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(nnx.Module):\n",
        "    \"\"\" Combines token embeddings (words in an input sentence) with\n",
        "    positional embeddings (the position of each word in a sentence).\n",
        "\n",
        "    Args:\n",
        "        maxlen (int): Matimum sequence length.\n",
        "        vocal_size (int): Vocabulary size.\n",
        "        embed_dim (int): Embedding dimensionality.\n",
        "        rngs (flax.nnx.Rngs): A Flax NNX stream of JAX PRNG keys.\n",
        "    \"\"\"\n",
        "    def __init__(self, maxlen: int, vocab_size: int, embed_dim: int, *, rngs: nnx.Rngs):\n",
        "        # Initialize token embeddings (using `flax.nnx.Embed`).\n",
        "        # Each unique word has an embedding vector.\n",
        "        self.token_emb = nnx.Embed(num_embeddings=vocab_size, features=embed_dim, rngs=rngs)\n",
        "        # Initialize positional embeddings (using `flax.nnx.Embed`).\n",
        "        self.pos_emb = nnx.Embed(num_embeddings=maxlen, features=embed_dim, rngs=rngs)\n",
        "\n",
        "    # Takes a token sequence (integers) and returns the combined token and positional embeddings.\n",
        "    def __call__(self, x):\n",
        "        # Generate a sequence of positions for the input tokens.\n",
        "        positions = jnp.arange(0, x.shape[1])[None, :]\n",
        "        # Look up the positional embeddings for each position in the input sequence.\n",
        "        position_embedding = self.pos_emb(positions)\n",
        "        # Look up the token embeddings for each token in the input sequence.\n",
        "        token_embedding = self.token_emb(x)\n",
        "        # Combine token and positional embeddings.\n",
        "        return token_embedding + position_embedding\n",
        "\n",
        "class MiniGPT(nnx.Module):\n",
        "    \"\"\" A miniGPT transformer model, inherits from `flax.nnx.Module`.\n",
        "\n",
        "    Args:\n",
        "        maxlen (int): Maximum sequence length.\n",
        "        vocab_size (int): Vocabulary size.\n",
        "        embed_dim (int): Embedding dimensionality.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        feed_forward_dim (int): Dimensionality of the feed-forward network.\n",
        "        num_transformer_blocks (int): Number of transformer blocks. Each block contains attention and feed-forward networks.\n",
        "        rngs (nnx.Rngs): A Flax NNX stream of JAX PRNG keys.\n",
        "    \"\"\"\n",
        "    # Initialize miniGPT model components.\n",
        "    def __init__(self, maxlen: int, vocab_size: int, embed_dim: int, num_heads: int, feed_forward_dim: int, num_transformer_blocks: int, rngs: nnx.Rngs):\n",
        "        # Initiliaze the `TokenAndPositionEmbedding` that combines token and positional embeddings.\n",
        "        self.embedding_layer = TokenAndPositionEmbedding(\n",
        "                    maxlen, vocab_size, embed_dim, rngs=rngs\n",
        "                )\n",
        "        # Create a list of `TransformerBlock` instances.\n",
        "        # Each block processes input sequences using attention and feed-forward networks.\n",
        "        self.transformer_blocks = [TransformerBlock(\n",
        "            embed_dim, num_heads, feed_forward_dim, rngs=rngs\n",
        "        ) for _ in range(num_transformer_blocks)]\n",
        "        # Initialize the output `flax.nnx.Linear` layer producing logits over the vocabulary for next-token prediction.\n",
        "        self.output_layer = nnx.Linear(in_features=embed_dim,\n",
        "                                       out_features=vocab_size,\n",
        "                                       rngs=rngs)\n",
        "\n",
        "    def __call__(self, inputs, training: bool = False):\n",
        "        # Pass the input tokens through the `embedding_layer` to get token embeddings.\n",
        "        # Apply each transformer block sequentially to the embedded input, use the `training` flag for the behavior of `flax.nnx.Dropout`.\n",
        "        x = self.embedding_layer(inputs)\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            x = transformer_block(x, training=training)\n",
        "        # Pass the output of the transformer blocks through the output layer,\n",
        "        # and obtain logits for each token in the vocabulary (for next token prediction).\n",
        "        outputs = self.output_layer(x)\n",
        "        return outputs\n",
        "\n",
        "    @nnx.jit\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = jax.lax.top_k(logits, k=top_k)\n",
        "        logits = nnx.softmax(logits)\n",
        "        return jax.random.choice(jax.random.PRNGKey(0), indices, p=logits)\n",
        "\n",
        "    @nnx.jit\n",
        "    def generate_step(self, padded_tokens, sample_index):\n",
        "        logits = self(padded_tokens)\n",
        "        next_token = self.sample_from(logits[0][sample_index])\n",
        "        return next_token\n",
        "\n",
        "    def generate_text(self, max_tokens, start_tokens):\n",
        "        generated = []\n",
        "        print(tokenizer.decode(start_tokens), flush=True, end='')\n",
        "        for i in range(max_tokens):\n",
        "            sample_index = len(start_tokens) + len(generated) - 1\n",
        "\n",
        "            padded_tokens = jnp.array((start_tokens + generated + [0] * (maxlen - len(start_tokens) - len(generated))))[None, :]\n",
        "            next_token = int(self.generate_step(padded_tokens, sample_index))\n",
        "            if next_token == tokenizer.encode('<|endoftext|>', allowed_special={'<|endoftext|>'})[0]:\n",
        "              break\n",
        "            generated.append(next_token)\n",
        "            # decode and print next_token\n",
        "            print(tokenizer.decode([next_token]), flush=True, end='')\n",
        "        return tokenizer.decode(start_tokens + generated)\n",
        "\n",
        "# Creates the miniGPT model with 4 transformer blocks.\n",
        "def create_model(rngs):\n",
        "    return MiniGPT(maxlen, vocab_size, embed_dim, num_heads, feed_forward_dim, num_transformer_blocks=4, rngs=rngs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igX_eoGNMTGR"
      },
      "source": [
        "Set some hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRhiDsCrMZRp"
      },
      "outputs": [],
      "source": [
        "vocab_size = tokenizer.n_vocab\n",
        "num_transformer_blocks = 8\n",
        "maxlen = 256\n",
        "embed_dim = 256\n",
        "num_heads = 8\n",
        "feed_forward_dim = 256\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "top_k = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1ci-HyMspJ"
      },
      "source": [
        "## Loading and preprocessing the data\n",
        "\n",
        "Data loading and preprocessing with [Grain](https://github.com/google/grain)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGUFsn1GMuzh"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TextDataset:\n",
        "    data: list\n",
        "    maxlen: int\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        # Use Tiktoken for tokenization\n",
        "        encoding = tokenizer.encode(self.data[idx], allowed_special={'<|endoftext|>'})[:self.maxlen]  # Tokenize and truncate\n",
        "        return encoding + [0] * (self.maxlen - len(encoding))  # Pad to maxlen\n",
        "\n",
        "def load_and_preprocess_data(file_path, batch_size, maxlen):\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "      text = f.read()\n",
        "\n",
        "    stories = text.split('<|endoftext|>')\n",
        "    stories = [story+'<|endoftext|>' for story in stories if story.strip()]\n",
        "    df = pd.DataFrame({'text': stories})\n",
        "    data = df['text'].dropna().tolist()\n",
        "    dataset = TextDataset(data, maxlen)\n",
        "\n",
        "    sampler = pygrain.IndexSampler(\n",
        "        len(dataset),\n",
        "        shuffle=False,\n",
        "        seed=42,\n",
        "        shard_options=pygrain.NoSharding(),\n",
        "        num_epochs=num_epochs,\n",
        "    )\n",
        "\n",
        "    dl = pygrain.DataLoader(\n",
        "        data_source=dataset,\n",
        "        sampler=sampler,\n",
        "        operations=[pygrain.Batch(batch_size=batch_size, drop_remainder=True)],\n",
        "    )\n",
        "\n",
        "    return dl\n",
        "\n",
        "text_dl = load_and_preprocess_data('TinyStories-train.txt', batch_size, maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVSD8KSM1um"
      },
      "source": [
        "## Defining the loss function and training step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rRuTmABNV4b"
      },
      "outputs": [],
      "source": [
        "# Defines the loss function using `optax.softmax_cross_entropy_with_integer_labels`.\n",
        "def loss_fn(model, batch):\n",
        "    logits = model(batch[0])\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch[1]).mean()\n",
        "    return loss, logits\n",
        "\n",
        "# Define the training step with the `flax.nnx.jit` transformation decorator.\n",
        "@nnx.jit\n",
        "def train_step(model: MiniGPT, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
        "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
        "    (loss, logits), grads = grad_fn(model, batch)\n",
        "    metrics.update(loss=loss, logits=logits, lables=batch[1])\n",
        "    optimizer.update(grads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5um2vkeUNckm"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Start training. It takes ~50 minutes on Colab.\n",
        "\n",
        "Note that for data parallel, we are sharding the training data along the `batch` axis using `jax.device_put` with `NamedeSharding`.\n",
        "\n",
        "We are also using the `jax.vmap` transformation to produce the target sequences faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysl6CsfENeJN",
        "outputId": "04a552c2-e9dd-42c7-f966-4ab2865166be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial generated text:\n",
            "Once upon a time infiltrated abunduitvicval methamphetamine360360 LevelsFortGb bonds {} pathwaysickey northwest� {} stoppingcre� {} scenario Vegan Captain Analysis northwest nomination {} FS {} commentary northwest See {} Woman {}Except FS constitute perished {} {} {}Nick nominationExcept {}Nick FS {} stopping Analysis Whites {} Whitescre lore Levelsval {} See gearfingerLucaped offence elder Types {}edIninkinguser FS Bruce Pell {} Levels FS {} {} Levels(- nomination FSShoulduit FS nomination Shattered deline emanc Levels Whites {} Whites {} Bruce {} FS {} {} Analysis unite Blackburn FSuesecarb firepower grasped nomination nomination graspedproblem Tang FS purple FS {} {} Levelsphalt {} {} Bruce {} BruceLucydia {} {} FS {}acial helic FS {} FS constitute perished {}absor northwestroidraviolet visceralproblem {} {} Analysis {}absor Broadcasting FS constitute {} Woman nomination {} FSMuch nond {} stoppinguniversaloun constitute perished {} retire {}netlast Shattered Whites {} FS {} {} commentary reservationscre Atom transistor Tang FSintensity {} dissatisfied {} Woman Captain {} FS constitute scoring Shatteredcre description(- {} FSumbledEEE Blackburncre Atom {}scl Twin sourcing {} northwest Intercept hiding {} escalation wil {} northwestroidExceptBT {} {} Woman tread escalation treasures {}scl FSMuch FS nominationscluces {}absor struggleuniversal {} {} dissatisfied FS {}absor survivoreteenth Levels Whites marscre Judges Judges Judges\n",
            "\n",
            "Step 50, Loss: 5.311988353729248, Elapsed Time: 47.13 seconds\n",
            "Generated text:\n",
            "Once upon a time a was a was was,,, was,,,,,,,., to,.,.,,..,.,.,.,.,.,.,.,.,.,....,..,.....................................\n",
            " the.\n",
            " the the the the the the the.\n",
            " the the the the the the the the the the the the the the the the...\n",
            " the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Judges Judges Judges\n",
            "\n",
            "Step 100, Loss: 4.009029865264893, Elapsed Time: 25.70 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl was very Lily. He was very he was very he was very he was so he was very a big, he was so happy. He was so happy. She was so happy. He was so happy. He was very happy. He was very her mommy. She was very happy. She was so happy. She was so happy. She said, but he was so happy. She was so happy. He was so happy. He was very happy. He was so happy. She was so happy. She was very happy. He was so happy. He was so happy. He was so happy. He!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Judges Judges Judges\n",
            "\n",
            "Step 150, Loss: 3.22125506401062, Elapsed Time: 25.15 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily. She was very happy. She was very happy. She was very happy.\n",
            "The little girl was so excited to the park.\n",
            "The little girl was so happy that she was so excited.\n",
            "The little girl was so happy. She was so excited.\n",
            "The little girl was so happy and she was so happy and she was so happy that she was so happy. She was so happy.\n",
            "\n",
            "\n",
            "Step 200, Loss: 2.981999158859253, Elapsed Time: 23.38 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her mommy. She loved to play with her mommy. She saw a big, Lily's mommy, she saw a big, she saw a big, she saw a big, she could not like to her mommy.\n",
            "Her mommy.\n",
            "Lily was too. She was too. She said, Lily said, she could not to her mommy.\n",
            "Lily was too. She said, Lily's mommy, Lily said, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"Yes, \"I'm sorry!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Judges Judges Judges\n",
            "\n",
            "Step 250, Loss: 2.90028977394104, Elapsed Time: 25.26 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her mom. She loved to play with her mom. She saw a big, \"Let's mom. She saw a big, \"I want to the garden. She asked her mom said, \"I want to the garden. She was so excited to the park. She said, \"I want to the park. She said, \"I want to the water. She said, \"I want to the water and said, \"I want to the park. She was so excited. She said, \"I want to the water. She was so happy. She said, \"I want to the water. She said, \"I want to the water. She said, \"I want to the water. She was so happy. She said, \"I can make it was so happy. She said, \"I want to the water.\n",
            "\n",
            "\n",
            "Step 300, Loss: 2.76497745513916, Elapsed Time: 24.73 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys, Lily. She had a big box. She loved to play with her mom and her mom.\n",
            "\"I want to be careful, Lily.\n",
            "\"I want to play with your toys!\" Lily said, Lily said, Lily said, Lily said, Lily said, \"I want to be careful, \"I want to be careful, \"I want to be careful, I have to be careful.\"\n",
            "\"I'm sorry, Lily and said, Lily said, \"I'm sorry, Lily said, \"I'm sorry, \"I'm sorry.\"\n",
            "\n",
            "\n",
            "Step 350, Loss: 2.7173972129821777, Elapsed Time: 24.55 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside and play outside in the park. One day, she saw a big tree. She saw a big tree. She wanted to go to the park. She was so she was so she was so happy and she was so happy to see what she was so she was so happy and she was so happy.\n",
            "Lily was so happy and she was so happy to see what she was so happy. She said, \"I want to go to the park. She said, \"I want to be careful.\"\n",
            "Lily and said, \"I want to be careful. She said, \"I'm sorry for help you. She said, \"I'm sorry, \"I'm sorry, \"I'm sorry, \"I'm sorry, Lily's okay.\"\n",
            "\n",
            "\n",
            "Step 400, Loss: 2.6128246784210205, Elapsed Time: 24.49 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside and play. One day, she saw a big, she went to the park. She wanted to go to the park.\n",
            "\"Look, Lily, Lily, Lily, Lily. \"I want to play with me!\" Lily said, \"I know what to go to the park.\n",
            "\"No, we can't worry, we can't find it.\"\n",
            "\"I want to play with the park.\n",
            "\"I know, Lily said, Lily. \"I know, Lily. \"I know, Lily's go to play with me.\"\n",
            "\"I'm sorry, Lily said, Lily said, \"I'm going to be careful.\"\n",
            "\"I'm sorry, Lily said, Lily and Lily and Lily and Lily's go to the park.\n",
            "\"Thank you.\"\n",
            "\"Thank you.\"\n",
            "\"Thank you.\"\n",
            "\"I'm sorry, Lily said, Lily said, Lily said, Lily said, Lily said, Lily and Lily said, Lily said, Lily said, Lily said, Lily and said, \"I'm sorry, Lily's okay, Lily's okay, Lily's okay, Lily's okay, Lily's okay, Lily's okay, Lily's! Judges Judges Judges\n",
            "\n",
            "Step 450, Loss: 2.492018938064575, Elapsed Time: 25.35 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl. She was very happy. She had a big and she had a big box. She was very sad.\n",
            "She had a special. She wanted to go to go to the store and started to cry.\n",
            "She saw a big smile. She wanted to cry. She said, \"I'm so you can I have to be careful. I have a new friend.\n",
            "The next day, the store to be brave. She said, \"Yes, you can be careful.\"\n",
            "The next day, the store and said, \"Yes, \"Yes, you can be careful, you can be careful.\"\n",
            "\n",
            "\n",
            "Step 500, Loss: 2.4384891986846924, Elapsed Time: 24.52 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and play with her toys. One day, Lily's mommy and her mommy's mommy and daddy. Lily didn't want to play with her toys.\n",
            "Lily's mommy and said, \"Mommy, Lily, Lily, Lily's okay, Lily's mommy, Lily's mommy's mommy, Lily's mommy, but Lily didn't want to play with her toys. Lily didn't want to help her mommy and her mommy. Lily didn't want to help her mommy and her mommy.\n",
            "Lily was sad because she didn't want to be careful. She said, \"I'm sorry, Lily, Lily, Lily, Lily, Lily, Lily, Lily, Lily, Lily, Lily and her mommy. Lily was happy to her mommy and said, \"Thank you, Lily, Lily, Lily, Lily, Lily, Lily, Lily, Lily, Lily. You can't have a good friend.\" Lily and said, \"Thank you, Lily, Lily, Lily, Lily, Lily, Lily, Lily, Lily and her mommy, Lily, Lily and her mommy, Lily's mom! Judges Judges Judges\n",
            "\n",
            "Step 550, Loss: 2.464111328125, Elapsed Time: 25.72 seconds\n",
            "Generated text:\n",
            "Once upon a time there was a little girl named Lily. She loved to play outside and dance. One day, she was playing outside. She was so excited to go to go to the park. She was so excited to go to the park.\n",
            "Lily was so excited to go to the park. She was so excited to go to the park. She was so happy and she had to go home. She was so happy to have a new toy.\n",
            "\n",
            "\n",
            "Step 600, Loss: 2.3867900371551514, Elapsed Time: 24.18 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the garden. One day, Lily's mommy's mommy and daddy. She saw a big, and asked her mommy if she could go on the ground. Lily said yes and they went to the store. Lily was so excited to see the store.\n",
            "Lily was so excited to see the store. She asked her mommy, \"Mommy, Lily's a big, Lily. Lily said, \"Mommy, Lily. You can't be careful.\" Lily said, \"Okay, Lily. You can't be careful.\" Lily said, \"Okay, Lily. You can't be careful.\" Lily said, \"Okay, Lily. You can't be careful.\" Lily said, \"Okay, Lily.\" Lily and Lily felt happy and said, \"Thank you for you to the store.\" Lily said, \"Thank you, Lily.\" Lily said, Lily and Lily said, \"Thank you, Lily.\" Lily said, \"Thank you, Lily. You are a good friend.\" Lily said, \"Yes, Lily. You are a great.\" Lily and Lily's mommy said, \"Okay, Lily. You are a great friend. You are a great! Judges Judges Judges\n",
            "\n",
            "Step 650, Loss: 2.246232032775879, Elapsed Time: 26.04 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Amy. She was very excited to go to the park. She was so excited to go to the park. She saw a big tree. She wanted to go to the tree and the tree. She asked her mom if she could go home. She said yes and they could help the tree.\n",
            "When the tree was done, the tree was so excited to go home. She was so excited to see the tree. She said she was so excited to go home. She was so excited to see the tree. She said she had to go home. She was so happy to the tree and thanked the tree.\n",
            "The end. She was so happy and thanked the tree for the tree. She thanked the tree and thanked the tree.\n",
            "\n",
            "\n",
            "Step 700, Loss: 2.2799911499023438, Elapsed Time: 24.93 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily. She was very excited to go on the beach. She saw a big, shiny and wanted to go on the beach. She asked her mom, \"What is a big, Lily?\" she said, \"It's a little girl. I'm going to the beach. I will be careful, but I don't know you need to be careful. I will be careful.\"\n",
            "Lily nodded and said, \"No, I will be careful. I will be careful.\"\n",
            "Lily was so excited to help her mom and said, \"No, I will be careful. I will be careful.\"\n",
            "Lily and Lily felt sad and said, \"No, I'm sorry, I'm sorry. I will be careful.\"\n",
            "Lily and Lily felt sad and said, \"No, I'm sorry, I'm sorry, I'm sorry. I'm sorry, I'm sorry, I'm sorry, I'm sorry, I don't you.\"\n",
            "Lily nodded and said, \"No, I'm sorry, I'm sorry, I'm sorry, I'm sorry, I'm sorry. I'm sorry, I'm sorry, I'm sorry, I'm sorry, I'm sorry, you.\"! Judges Judges Judges\n",
            "\n",
            "Step 750, Loss: 2.2158865928649902, Elapsed Time: 25.94 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her favorite toy. She would always run around her room and see her room and see her room. She saw a big, and it was so she wanted to play with her doll.\n",
            "Her mom said, \"Mom, Lily, Lily, Lily, I'm sorry, Lily. I'm sorry I'm sorry for you.\" Lily was so happy and she said, \"No, Lily. I will be careful with your doll.\"\n",
            "Lily was so happy and hugged her doll. She said, \"No, Lily. You can't have to be careful. You have to be careful with your doll. You can't have to play with your doll.\"\n",
            "Lily was so happy and she hugged her doll. She said, \"Thank you, Lily. You are so happy and kind. You are so happy to have to play with your doll. You are so happy and I love to play with your doll.\n",
            "\n",
            "\n",
            "Step 800, Loss: 2.108785629272461, Elapsed Time: 25.84 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily and Lily. She loved to play outside in the sun and play. One day, Lily's mommy and Lily went to the park with her mommy. Lily saw a big, and Lily and Lily. She asked her mommy if she could play with her mommy for her mommy for her mommy. Lily said, \"Mommy, Lily, Lily, Lily's mommy's mommy's okay?\"\n",
            "Lily asked her mommy for her mommy for her mommy and daddy. Lily didn't want to go to the park with her mommy. Lily didn't want to play with her mommy, but she didn't want to be careful. Lily didn't want to share her toys with her mommy. Lily was sad and didn't want to share her toys anymore.\n",
            "Lily learned that sometimes we have to be careful when we can be careful when we can be careful when we can be okay to be careful when we have to be careful when we can be okay to others.\"\n",
            "\n",
            "\n",
            "Step 850, Loss: 2.097984790802002, Elapsed Time: 25.53 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and play. One day, she went to the park with her mom. She saw a big tree. Lily wanted to play with her toys.\n",
            "Lily's mommy said, \"Mommy, Lily. It is not nice. It is not nice. It is not nice. It is not nice. It is not nice. It is not nice. It is not nice. Lily.\n",
            "Lily did not like the other. She did not like the other. She did not like the other. She did not like the other. She did not like the other kids. She did not know what to do. She did not know what to do. She did not know what to do.\n",
            "Her mommy and dad came to the park. They were not happy. They did not like the kids. They did not like the kids. They were not like the kids. They did not like the kids. They did not like the kids. They were not like to share.\n",
            "\n",
            "\n",
            "Step 900, Loss: 2.0876221656799316, Elapsed Time: 25.70 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her friends. One day, she saw a big, red ball. She wanted to play with it.\n",
            "Lily asked her mom if she could play with her toys, but her mom said no. Her mom said no, \"I can't have to clean it.\"\n",
            "Her mom said, \"I want to play with it.\" Lily said, \"Okay, it's too high.\"\n",
            "Her mom said, \"I can't have it.\" Lily said, \"Okay, it's not nice.\"\n",
            "Her mom said, \"I can't wait to go to the park.\" Lily was happy and said, \"Thank you, Lily. You're welcome.\"\n",
            "Lily and her mom went to the park, and they played together. Lily was happy and they played together.\n",
            "\n",
            "\n",
            "Step 950, Loss: 2.1647396087646484, Elapsed Time: 25.61 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her toys. One day, she saw a big box in the box. She wanted to play with it, but she was too high. She wanted to play with it, but she was too fast.\n",
            "Lily's mom came to the box and saw her and said, \"Hi, I am a little girl. I am a little girl. I'm not to play with you.\"\n",
            "Lily was very happy and said, \"I'm sorry, I'm sorry, I'm sorry you. I'm sorry for my friend.\"\n",
            "Lily and her mom went to the store and saw the box. She saw the box and asked her mom what was wrong. Her mom said, \"I'm sorry, Lily. I'm sorry, but I'm sorry you can't find it. I will be careful.\"\n",
            "Lily felt sad and said, \"I'm sorry, I'm sorry, I'm sorry. I'm sorry for you. I'm sorry.\"\n",
            "\n",
            "\n",
            "Step 1000, Loss: 1.9453978538513184, Elapsed Time: 25.72 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her favorite toy was a big, and she always wanted to play with her toys. One day, Lily's mom asked her to help her. Lily was very sad and didn't want to go to the park.\n",
            "Her mom said, \"No, Lily, Lily, I want to play with my toy car. But Lily didn't want to play with her toy car, but her mom said no. Lily was sad and didn't want to play with her toy car. She said, \"No, Lily, Lily, you can't have to go to the toy car, but you have to be careful when you have to be careful when you don't want to go to the park. But Lily didn't want to go to the toy car, but she didn't want to play with her toy car.\n",
            "Lily was sad and cried. She cried and cried, but she didn't want to go to the toy car. She was sad and cried. She cried and cried and cried.\n",
            "Lily felt sad and cried. She cried and cried out of her mom. She was sad and cried. She cried and cried out of her mom.\n",
            "! Judges Judges Judges\n",
            "\n",
            "Step 1050, Loss: 2.0212814807891846, Elapsed Time: 26.12 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily and her mom went to the park. Lily was so excited to see her mom and dad. Lily was so excited to see her dad and they were going to the park.\n",
            "When Lily got home, she saw a big, shiny butterfly. She was so excited! She ran to the butterfly and ran to it. Lily was so excited! She ran to the butterfly and ran to the butterfly. She was so happy!\n",
            "When Lily got home, she was so happy! She hugged her mom and said, \"It's a big, Lily! I'm so glad you like to be careful.\" Lily smiled and said, \"Yes, Lily. I love to play with you.\"\n",
            "\n",
            "\n",
            "Step 1100, Loss: 1.9757156372070312, Elapsed Time: 25.10 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her toys. One day, she went to the park with her mommy and daddy. They were very happy and loved to play.\n",
            "After they were playing, Lily's mommy said, \"Mommy, let's go to the park with the swings and slide!\" Lily was so happy and said, \"Thank you, Lily. You're so happy!\" Her mommy said, \"Thank you for helping me.\"\n",
            "Lily was happy and said, \"Thank you, Lily. I love you, Lily.\" Her mommy said, \"Thank you for helping me.\" Lily said, \"Thank you, Lily. I love you!\" Her mommy smiled and said, \"Thank you for helping me.\" From that day on, Lily and her mommy played together every day.\n",
            "\n",
            "\n",
            "Step 1150, Loss: 1.9473527669906616, Elapsed Time: 25.31 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the sun. One day, Lily's friend, came over to play.\n",
            "\"Hi Lily!\" said Lily.\n",
            "\"I'm sorry,\" said Lily.\n",
            "\"I'm sorry,\" said Lily.\n",
            "\"I'm sorry,\" said Lily.\n",
            "\"Don't worry,\" said her friend.\n",
            "\"I'm sorry,\" said Lily.\n",
            "\"Don't worry,\" replied her friend.\n",
            "\"I'll help you.\"\n",
            "Lily was happy and said, \"I'll help you.\"\n",
            "Lily was happy to help. She went to the park and found a new friend.\n",
            "\"Thank you, Lily,\" said Lily.\n",
            "\"Thank you,\" said Lily.\n",
            "\"Thank you,\" said Lily.\n",
            "\"Thank you,\" replied Lily.\n",
            "\"Thank you,\" said Lily.\n",
            "\"Thank you,\" said Lily.\n",
            "\"I'm glad you can help me,\" said Lily.\n",
            "\n",
            "\n",
            "Step 1200, Loss: 1.884827733039856, Elapsed Time: 25.86 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her toys. One day, she went to the park with her mom. She saw a big tree with a big tree. Lily wanted to play with her mom.\n",
            "Lily asked her mom if she could play with her. Her mom said yes, but Lily was very happy. She said she had a fun day. Her mom said, \"I want to play with you. I want to play with you.\" Lily said, \"Okay, Lily. I will play with you.\"\n",
            "Lily was happy and said, \"Thank you, Lily. I love you!\" Her mom said, \"Thank you, Lily. I love you.\"\n",
            "\n",
            "\n",
            "Step 1250, Loss: 1.9007595777511597, Elapsed Time: 25.05 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily. She loved to play with her toys. One day, she went to the park with her mom. She saw a big, red ball. She wanted to play with it.\n",
            "Lily ran to the park, but she saw a big dog. The dog was very cute and had a big dog. Lily was sad. She wanted to play with her toys.\n",
            "Lily's mom said, \"Don't be scared, Lily, I can't be sad. But be scared, but I don't have to be mean to play with you.\"\n",
            "Lily was sad and angry. She said, \"Don't worry, Lily. I will be sad, Lily. I will be sad and not be mean to share. I will be friends.\"\n",
            "Lily was sad and angry. She wanted to play with her friends. She said, \"I don't want to play with you, Lily. I want to play with my ball, but I don't want to play with you.\"\n",
            "Lily and her friends played with the ball. They played together and had fun. They had a great day and had fun.\n",
            "\n",
            "\n",
            "Step 1300, Loss: 1.976030707359314, Elapsed Time: 26.09 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside and play. One day, she went to the park with her mommy. She saw a big slide and wanted to go on it.\n",
            "Lily asked her mommy if she could go to the slide. Her mommy said yes, so they went to the slide and the slide down. Lily was so happy to see the slide and the slide. She was so happy to see the slide and the slide.\n",
            "When they got home, Lily's mommy said to her. Lily was so happy to see her mommy and daddy. They played together and had fun. Lily was happy to see her new slide and her. She was so happy to see her new slide and the slide.\n",
            "\n",
            "\n",
            "Step 1350, Loss: 1.811220645904541, Elapsed Time: 25.59 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her toys. One day, Lily's mommy told her that they were going to a park. Lily was very happy and said they would visit her grandma.\n",
            "Lily was very happy and said, \"Thank you, Lily. You are very good at my friends.\" Her grandma said, \"You can have a new friend.\" Lily was happy and said, \"Thank you, Lily. You are a good friend.\" Her grandma said, \"You are a good friend.\"\n",
            "Lily was happy and said, \"Thank you, Lily. Let's play together.\" Her grandma said, \"You're welcome, Lily. Let's go to the park and play together.\" Lily said, \"Okay, let's go play together.\"\n",
            "Lily and her grandma said, \"Okay, let's go home and play together.\" They played together and had a fun day. They played together and had a great time.\n",
            "\n",
            "\n",
            "Step 1400, Loss: 1.846255898475647, Elapsed Time: 25.60 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily. She loved to play with her friends. One day, she went to the park to play. She saw a big, red ball. She wanted to play with it.\n",
            "Her mom said, \"Let's play with the ball!\" Lily was excited. She ran to the ball and ran to the ball.\n",
            "When she got to the park, she saw a big, yellow ball. It was so big and round. Lily was so happy. She ran to the ball and ran to the ball.\n",
            "When she got home, she saw a big dog. The dog was barking and Lily. The dog was scared and ran away. Lily was sad and scared. She ran away and ran away.\n",
            "\n",
            "\n",
            "Step 1450, Loss: 1.7977628707885742, Elapsed Time: 25.17 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big tree with many branches. She wanted to climb it, but she didn't want to get wet.\n",
            "Lily asked her mom if she could help her mom. Her mom said yes and they went to the tree. Lily was very happy and she saw a big tree. She wanted to climb the tree and climb it.\n",
            "Lily asked her mom if she could help her mom. Her mom said yes and gave her a big hug. Lily was happy and she could help her mom. She said she would help her mom and dad.\n",
            "\n",
            "\n",
            "Step 1500, Loss: 1.8275420665740967, Elapsed Time: 24.98 seconds\n",
            "Generated text:\n",
            "Once upon a time there was a little girl who loved to play. She had a toy that she loved to play with her toy cars. One day, she found a new toy that was very special. She wanted to play with it, so she decided to play with it. She ran and played with it all day long.\n",
            "When she got to the toy car, she saw a big, red car and it was so happy. She ran to the car and played with it all day long. She was so happy that she had made her favorite toy car.\n",
            "\n",
            "\n",
            "Step 1550, Loss: 1.781172275543213, Elapsed Time: 24.75 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her favorite toy. One day, Lily's mom said, \"Lily, it's time to go to the park. It's not nice to play with it. It's not nice. Lily wanted to play with it.\n",
            "Lily went to the park with her mom. She saw a big red ball on the ground. She wanted to play with it. She ran to it and tried to catch it.\n",
            "She tried to catch it, but it was too high. She tried to run away, but it was too late. Lily fell down and hurt her. She hurt her mom. Her mom was sad.\n",
            "Her mom came to help her. She saw her mom and said, \"Don't worry, Lily. I will help you. I will help you.\" Lily felt better. She went to the park and saw that her mom was not happy.\n",
            "\n",
            "\n",
            "Step 1600, Loss: 1.7957417964935303, Elapsed Time: 25.54 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the sun. One day, she found a shiny rock. She picked it up and put it in her pocket.\n",
            "Lily was so excited to see the rock. She ran to the rock and started to cry. Her mom came to help her.\n",
            "\"Don't worry, Lily,\" her mom said.\n",
            "\"Don't worry, we can find it.\"\n",
            "Lily was so happy to see the rock. She picked it up and put it in the rock.\n",
            "\"Thank you for helping me,\" her mom said.\n",
            "Lily was so happy to have found the rock. She thanked the rock for her mom and said goodbye.\n",
            "\n",
            "\n",
            "Step 1650, Loss: 1.8778215646743774, Elapsed Time: 25.05 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily went to the park with her mom. Lily loved to play with her friends. One day, Lily saw a big slide on the ground. She wanted to try it, but it was too high.\n",
            "Lily asked her mom if she could go. Her mom said yes, but Lily was very happy. She said it was too high for her.\n",
            "Lily was so excited to see her mommy. She said, \"Mommy, can we play with the slide?\"\n",
            "Her mom smiled and said, \"Of course, Lily. We can go to the slide and slide. Let's go to the slide and slide.\" Lily said, \"Okay, let's go.\"\n",
            "Lily and her mom went to the slide and saw that Lily was so excited. She said, \"Okay, let's go!\"\n",
            "Lily said, \"Okay, let's go!\" she said, \"Yes, let's go!\"\n",
            "They went to the slide and slides and Lily's slide. They had fun. They had fun playing and having fun. Lily was happy to see the slide and said, \"Thank you, Lily. You are so good at my slide!\"\n",
            "\n",
            "\n",
            "Step 1700, Loss: 1.7115627527236938, Elapsed Time: 25.94 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily went to the beach. She saw a big boat in the water. She wanted to sail the boat, so she asked her mom to help her.\n",
            "Her mom said, \"That's a boat is so we can sail on the boat.\" Lily was so excited to see the boat. She said, \"But the boat is too far away.\"\n",
            "Lily was so excited. She ran to the boat and the boat. She was so excited to see the boat and the boat. She ran to the boat and fast.\n",
            "When she got closer, she saw the boat was so excited. She was so excited to see the boat and the boat. She ran to the boat and jumped on the boat.\n",
            "When she got back home, she was so happy. She thanked the boat for the boat and the boat.\n",
            "The boat was so happy and the boat was safe. Lily and her mom hugged her and said, \"Thank you, mom, mom, mom, mom, mom, can you can still see the boat.\"\n",
            "\n",
            "Final generated text:\n",
            "Once upon a time, a little girl named Lily went to the park. She saw a big slide and wanted to go on it. She picked it up and started to slide.\n",
            "\"Look, Lily, I want to slide!\" she said.\n",
            "\"No, Lily, it's mine!\" Lily said.\n",
            "\"No, Lily. You don't want to climb the slide. You can't climb the slide.\"\n",
            "Lily was sad. She wanted to climb the slide, but she was not.\n",
            "Lily was sad and started to cry. She wanted to climb the slide. She climbed up the ladder and slid down. She slid down the slide and slid down.\n",
            "\"Come on, Lily, Lily. You are not nice. You are not nice. You are not nice. You are not nice. You are not nice. You are not nice. You are not nice. You are not nice. You are not nice. You are not nice. You are not mean to hurt. You are not mean. You are not mean to hurt you. You are not mean to hurt you. You are sorry. You are sorry and sorry.\n",
            "Lily was sorry and sorry. She did not mean to hurt her feelings. She did not want! Judges Judges Judges"
          ]
        }
      ],
      "source": [
        "model = create_model(rngs=nnx.Rngs(0))\n",
        "optimizer = nnx.Optimizer(model, optax.adam(1e-3))\n",
        "metrics = nnx.MultiMetric(\n",
        "  loss=nnx.metrics.Average('loss'),\n",
        ")\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "start_prompt = \"Once upon a time\"\n",
        "start_tokens = tokenizer.encode(start_prompt)[:maxlen]\n",
        "print(f\"Initial generated text:\")\n",
        "generated_text = model.generate_text(\n",
        "    maxlen, start_tokens\n",
        ")\n",
        "\n",
        "metrics_history = {\n",
        "  'train_loss': [],\n",
        "}\n",
        "\n",
        "prep_target_batch = jax.vmap(lambda tokens: jnp.concatenate((tokens[1:], jnp.array([0]))))\n",
        "\n",
        "step = 0\n",
        "\n",
        "start_time = time.time()\n",
        "for batch in text_dl:\n",
        "    if len(batch) % len(jax.devices()) != 0:\n",
        "      continue  # skip the remaining elements\n",
        "    input_batch = jnp.array(jnp.array(batch).T)\n",
        "    target_batch = prep_target_batch(input_batch)\n",
        "    train_step(model, optimizer, metrics, (input_batch, target_batch))\n",
        "\n",
        "    if (step + 1) % 50 == 0:\n",
        "      for metric, value in metrics.compute().items():\n",
        "          metrics_history[f'train_{metric}'].append(value)\n",
        "      metrics.reset()\n",
        "\n",
        "      elapsed_time = time.time() - start_time\n",
        "      print(f\"\\n\\nStep {step + 1}, Loss: {metrics_history['train_loss'][-1]}, Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "      start_time = time.time()\n",
        "\n",
        "      print(f\"Generated text:\")\n",
        "      generated_text = model.generate_text(\n",
        "          maxlen, start_tokens\n",
        "      )\n",
        "\n",
        "    step += 1\n",
        "\n",
        "# Final text generation\n",
        "print(f\"\\nFinal generated text:\")\n",
        "generated_text = model.generate_text(\n",
        "    maxlen, start_tokens\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thaLs6TD0lt5"
      },
      "source": [
        "Visualize the training loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "B6Eg1Cz2y_iP",
        "outputId": "ae354b70-9675-4094-c2ce-a57cbd5607a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(metrics_history['train_loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB-ExEt1Zl1C"
      },
      "source": [
        "As you can see, the model goes from generating completely random words at the beginning to generating sensible tiny stories at the end of the training. So essentially we have pretrained a small LLM to write tiny stories for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soPqiR1JNmjf"
      },
      "source": [
        "## Saving the checkpoint\n",
        "\n",
        "Save the model checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkoFGCgSZ1yz",
        "outputId": "500617ab-c5d1-49f5-86b2-88a410410a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array_metadatas       d\t\t      _METADATA        _sharding\n",
            "_CHECKPOINT_METADATA  manifest.ocdbt  ocdbt.process_0\n"
          ]
        }
      ],
      "source": [
        "import orbax.checkpoint as orbax\n",
        "\n",
        "state = nnx.state(model)\n",
        "\n",
        "checkpointer = orbax.PyTreeCheckpointer()\n",
        "checkpointer.save('/content/save', state)\n",
        "\n",
        "# Make sure the files are there\n",
        "!ls /content/save/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,md:myst"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}