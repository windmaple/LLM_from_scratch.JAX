{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":471295,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":379972,"modelId":239405},{"sourceId":470091,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":217697,"modelId":239405}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GPT2 DPO finetuning\n\nThis notebook demonstrates how to finetune a instruction-tuned GPT2(124M) model with [Direct Preference Optimization](https://arxiv.org/pdf/2305.18290). Note that this notebook only works on Kaggle TPU v3 or Clout TPU v3+ (Colab TPU v2 simply does not have enough HBM).","metadata":{"id":"rvP1eNN_pExM"}},{"cell_type":"markdown","source":"## Determine platform","metadata":{"id":"LD3bo9FxhrTE"}},{"cell_type":"code","source":"import os\nif os.path.exists('/kaggle/'):\n  platform = \"Kaggle\"\nelse:\n  # Assume using Cloud TPU otherwise\n  platform = \"GCP\"","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:36.783670Z","iopub.execute_input":"2025-07-16T08:10:36.783949Z","iopub.status.idle":"2025-07-16T08:10:36.800925Z","shell.execute_reply.started":"2025-07-16T08:10:36.783924Z","shell.execute_reply":"2025-07-16T08:10:36.796280Z"},"id":"7XcEXnSbhhKV","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Setup\n\nInstall JAX and Flax first.","metadata":{"id":"hTmz5Cbco7n_"}},{"cell_type":"code","source":"!pip install -q jax-ai-stack[grain]\nif platform == \"Colab\": # temp workaround on Colab (https://github.com/jax-ml/jax-ai-stack/issues/149)\n  !pip install -Uq \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n!pip install -Uq tiktoken matplotlib kaggle wandb tpu-info datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-07-16T08:10:36.805064Z","iopub.execute_input":"2025-07-16T08:10:36.806070Z","iopub.status.idle":"2025-07-16T08:10:45.730314Z","shell.execute_reply.started":"2025-07-16T08:10:36.806027Z","shell.execute_reply":"2025-07-16T08:10:45.726736Z"},"id":"6zMsOIc7ouCO","outputId":"e99591ab-c664-4e18-8d87-fb092165876e","trusted":true},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Confirm we have TPUs set up.","metadata":{"id":"6cWxBvz6bZDd"}},{"cell_type":"code","source":"import jax\njax.devices()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-07-16T08:10:45.733110Z","iopub.execute_input":"2025-07-16T08:10:45.733355Z","iopub.status.idle":"2025-07-16T08:10:49.220466Z","shell.execute_reply.started":"2025-07-16T08:10:45.733330Z","shell.execute_reply":"2025-07-16T08:10:49.215515Z"},"id":"uZUaKdi5bSEN","outputId":"4d72a412-2f71-486b-e41f-6b35e20eb0a5","trusted":true},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1752653446.244167    3695 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"Take care of the imports.","metadata":{"id":"sKE2uUafLobI"}},{"cell_type":"code","source":"import jax\nimport jax.numpy as jnp\nimport flax.nnx as nnx\nimport optax, orbax\nfrom collections import Counter\nfrom dataclasses import dataclass\nfrom jax.experimental import mesh_utils\nfrom jax.sharding import Mesh, PartitionSpec as P, NamedSharding\nimport numpy as np\nimport tiktoken, time, wandb\nfrom huggingface_hub import snapshot_download\nfrom safetensors import safe_open\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:49.221567Z","iopub.execute_input":"2025-07-16T08:10:49.221869Z","iopub.status.idle":"2025-07-16T08:10:50.712682Z","shell.execute_reply.started":"2025-07-16T08:10:49.221844Z","shell.execute_reply":"2025-07-16T08:10:50.708194Z"},"id":"MKYFNOhdLq98","trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Build the model\n\nDefine the device mesh.\n","metadata":{"id":"rPyt7MV6prz1"}},{"cell_type":"code","source":"mesh = Mesh(mesh_utils.create_device_mesh((8, 1)), ('batch', 'model'))","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:50.714986Z","iopub.execute_input":"2025-07-16T08:10:50.716157Z","iopub.status.idle":"2025-07-16T08:10:50.725714Z","shell.execute_reply.started":"2025-07-16T08:10:50.716131Z","shell.execute_reply":"2025-07-16T08:10:50.720762Z"},"id":"xuMlCK3Q8WJD","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"We are going to use the GPT-2 tokenizer via OpenAI's [Tiktoken](https://github.com/openai/tiktoken) library.","metadata":{"id":"_ZKdhNo98NgG"}},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:50.728021Z","iopub.execute_input":"2025-07-16T08:10:50.728835Z","iopub.status.idle":"2025-07-16T08:10:51.016609Z","shell.execute_reply.started":"2025-07-16T08:10:50.728810Z","shell.execute_reply":"2025-07-16T08:10:51.012515Z"},"id":"iWbkk1V7-Isg","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Set some hyperparameters.","metadata":{"id":"igX_eoGNMTGR"}},{"cell_type":"code","source":"vocab_size = tokenizer.n_vocab\nGPT2_variant = \"GPT2\"\n\nnum_transformer_blocks = 12\nseqlen = 1024\nembed_dim = 768\nnum_heads = 12\nfeed_forward_dim = 4 * embed_dim\nbatch_size = 64\ndropout_rate = 0.1\n\ninit_learning_rate = 1e-5 #5e-4\nweight_decay = 1e-1\ntop_k = 10\nsampling_temp = 2\ndtype = jnp.bfloat16\nparam_dtype = jnp.float32\nbeta = 0.1\nmax_steps = 200","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:51.017607Z","iopub.execute_input":"2025-07-16T08:10:51.017821Z","iopub.status.idle":"2025-07-16T08:10:51.028164Z","shell.execute_reply.started":"2025-07-16T08:10:51.017801Z","shell.execute_reply":"2025-07-16T08:10:51.023657Z"},"id":"GRhiDsCrMZRp","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Now define the model architecture, which is the same as in our previous instruction tuning notebook.","metadata":{"id":"0XHQ0BQ9-KIj"}},{"cell_type":"code","source":"def causal_attention_mask(seq_len):\n    return jnp.tril(jnp.ones((seq_len, seq_len), dtype=jnp.bool_))\n\nclass CustomMHA(nnx.Module):\n    def __init__(self, embed_dim, num_heads, dropout_rate, layer_idx, rngs):\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // self.num_heads\n        self.embed_dim = embed_dim\n\n        kernel_init = nnx.with_partitioning(\n            nnx.initializers.xavier_uniform(), (P(None, \"model\"),)\n        )\n\n        self.query = nnx.Linear(\n            embed_dim, embed_dim, rngs=rngs, use_bias=False, kernel_init=kernel_init\n        )\n        self.key = nnx.Linear(\n            embed_dim, embed_dim, rngs=rngs, use_bias=False, kernel_init=kernel_init\n        )\n        self.value = nnx.Linear(\n            embed_dim, embed_dim, rngs=rngs, use_bias=False, kernel_init=kernel_init\n        )\n        self.out = nnx.Linear(\n            embed_dim, embed_dim, rngs=rngs, use_bias=False, kernel_init=kernel_init\n        )\n\n        self.q_bias = nnx.Param(\n            jnp.zeros((embed_dim,), dtype=param_dtype), sharding=P(\"model\")\n        )\n        self.k_bias = nnx.Param(\n            jnp.zeros((embed_dim,), dtype=param_dtype), sharding=P(\"model\")\n        )\n        self.v_bias = nnx.Param(\n            jnp.zeros((embed_dim,), dtype=param_dtype), sharding=P(\"model\")\n        )\n\n        self.out_bias = nnx.Param(\n            jnp.zeros((embed_dim,), dtype=param_dtype), sharding=P(\"model\")\n        )\n\n        self.dropout = nnx.Dropout(dropout_rate)\n\n    def __call__(\n        self, x, mask, padding_mask=None, training: bool = False, rngs: nnx.Rngs = None\n    ):\n        batch_size, seq_len, _ = x.shape\n\n        q = self.query(x) + self.q_bias\n        k = self.key(x) + self.k_bias\n        v = self.value(x) + self.v_bias\n\n        q = q.reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(\n            (0, 2, 1, 3)\n        )\n        k = k.reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(\n            (0, 2, 1, 3)\n        )\n        v = v.reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(\n            (0, 2, 1, 3)\n        )\n\n        attn_weights = jnp.matmul(q, k.transpose((0, 1, 3, 2))) / jnp.sqrt(\n            self.head_dim\n        )\n\n        combined_mask = mask\n        if padding_mask is not None:\n            combined_mask = jnp.logical_and(mask, padding_mask)\n\n        if combined_mask is not None:\n            attn_weights = jnp.where(combined_mask, attn_weights, -jnp.inf)\n\n        attn_weights = nnx.softmax(attn_weights, axis=-1)\n        attn_weights = self.dropout(attn_weights, deterministic=not training, rngs=rngs)\n\n        attn_output = jnp.matmul(attn_weights, v)\n        attn_output = attn_output.transpose((0, 2, 1, 3)).reshape(\n            (batch_size, seq_len, self.embed_dim)\n        )\n\n        output = self.out(attn_output) + self.out_bias\n        return output\n\n\nclass TransformerBlock(nnx.Module):\n    def __init__(\n        self,\n        embed_dim: int,\n        num_heads: int,\n        ff_dim: int,\n        dropout_rate: float,\n        rngs: nnx.Rngs,\n        layer_idx: int,\n    ):\n        self.layer_norm1 = nnx.LayerNorm(\n            epsilon=1e-6,\n            num_features=embed_dim,\n            scale_init=nnx.with_partitioning(\n                nnx.initializers.ones_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            bias_init=nnx.with_partitioning(\n                nnx.initializers.zeros_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n        self.mha = CustomMHA(embed_dim, num_heads, dropout_rate, layer_idx, rngs)\n        self.dropout1 = nnx.Dropout(rate=dropout_rate)\n        self.layer_norm2 = nnx.LayerNorm(\n            epsilon=1e-6,\n            num_features=embed_dim,\n            scale_init=nnx.with_partitioning(\n                nnx.initializers.ones_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            bias_init=nnx.with_partitioning(\n                nnx.initializers.zeros_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n        self.linear1 = nnx.Linear(\n            in_features=embed_dim,\n            out_features=ff_dim,\n            kernel_init=nnx.with_partitioning(\n                nnx.initializers.xavier_uniform(), NamedSharding(mesh, P(None, \"model\"))\n            ),\n            bias_init=nnx.with_partitioning(\n                nnx.initializers.zeros_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n        self.linear2 = nnx.Linear(\n            in_features=ff_dim,\n            out_features=embed_dim,\n            kernel_init=nnx.with_partitioning(\n                nnx.initializers.xavier_uniform(), NamedSharding(mesh, P(None, \"model\"))\n            ),\n            bias_init=nnx.with_partitioning(\n                nnx.initializers.zeros_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n        self.dropout2 = nnx.Dropout(rate=dropout_rate)\n\n    def __call__(\n        self, inputs, padding_mask=None, training: bool = False, rngs: nnx.Rngs = None\n    ):\n        input_shape = inputs.shape\n        bs, seq_len, emb_sz = input_shape\n\n        attention_output = self.mha(\n            self.layer_norm1(inputs),\n            mask=causal_attention_mask(seq_len),\n            padding_mask=padding_mask,\n            training=training,\n            rngs=rngs,\n        )\n        x = inputs + self.dropout1(\n            attention_output, deterministic=not training, rngs=rngs\n        )\n\n        # MLP\n        mlp_output = self.linear1(self.layer_norm2(x))\n        mlp_output = nnx.gelu(mlp_output)\n        mlp_output = self.linear2(mlp_output)\n        mlp_output = self.dropout2(mlp_output, deterministic=not training, rngs=rngs)\n\n        return x + mlp_output\n\n\nclass TokenAndPositionEmbedding(nnx.Module):\n    def __init__(\n        self,\n        seqlen: int,\n        vocab_size: int,\n        embed_dim: int,\n        rngs: nnx.Rngs,\n    ):\n        self.token_emb = nnx.Embed(\n            num_embeddings=vocab_size,\n            features=embed_dim,\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n        self.pos_emb = nnx.Embed(\n            num_embeddings=seqlen,\n            features=embed_dim,\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n\n    def __call__(self, x):\n        positions = jnp.arange(0, x.shape[1])[None, :]\n        position_embedding = self.pos_emb(positions)\n        token_embedding = self.token_emb(x)\n        return self.token_emb, token_embedding + position_embedding\n\n\nclass GPT2(nnx.Module):\n    def __init__(\n        self,\n        seqlen: int,\n        vocab_size: int,\n        embed_dim: int,\n        num_heads: int,\n        rate: float,\n        feed_forward_dim: int,\n        num_transformer_blocks: int,\n        rngs: nnx.Rngs,\n    ):\n        self.embedding_layer = TokenAndPositionEmbedding(\n            seqlen, vocab_size, embed_dim, rngs=rngs\n        )\n        self.dropout = nnx.Dropout(rate=rate)\n\n        self.transformer_blocks = [\n            TransformerBlock(\n                embed_dim,\n                num_heads,\n                feed_forward_dim,\n                dropout_rate,\n                rngs=rngs,\n                layer_idx=i,\n            )\n            for i in range(num_transformer_blocks)\n        ]\n\n        self.layer_norm = nnx.LayerNorm(\n            epsilon=1e-6,\n            num_features=embed_dim,\n            scale_init=nnx.with_partitioning(\n                nnx.initializers.ones_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            bias_init=nnx.with_partitioning(\n                nnx.initializers.zeros_init(), NamedSharding(mesh, P(\"model\"))\n            ),\n            dtype=dtype,\n            param_dtype=param_dtype,\n            rngs=rngs,\n        )\n\n    def __call__(\n        self, inputs, padding_mask=None, training: bool = False, rngs: nnx.Rngs = None\n    ):\n        token_embedding, x = self.embedding_layer(inputs)\n        x = self.dropout(x, deterministic=not training, rngs=rngs)\n        for transformer_block in self.transformer_blocks:\n            x = transformer_block(\n                x, padding_mask=padding_mask, training=training, rngs=rngs\n            )\n        x = self.layer_norm(x)\n        outputs = token_embedding.attend(x)\n        return outputs\n\n    @staticmethod\n    @nnx.jit\n    def sample_from(logits, key):\n        logits, indices = jax.lax.top_k(logits, k=top_k)\n        logits = nnx.softmax(logits / sampling_temp)\n        return jax.random.choice(key, indices, p=logits)\n\n    @staticmethod\n    @nnx.jit\n    def generate_step_static(params, static_def, padded_tokens, length, key):\n        padding_mask = jnp.arange(seqlen) < length\n        padding_mask = padding_mask.reshape(1, 1, 1, seqlen)\n\n        model = nnx.merge(params, static_def)\n        logits = model(padded_tokens, padding_mask=padding_mask, training=False)\n        last_token_logits = logits[:, length - 1, :]\n\n        key, subkey = jax.random.split(key)\n        next_token = GPT2.sample_from(jnp.squeeze(last_token_logits), subkey)\n        return next_token\n\n    def generate_text(self, max_tokens, start_tokens):\n        key = jax.random.PRNGKey(int(time.time()))\n\n        params, static_def = nnx.split(self)\n\n        tokens = jnp.array(start_tokens, dtype=jnp.int32)[None, :]\n        end_token = tokenizer.encode(\n            \"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}\n        )[0]\n\n        current_len = tokens.shape[1]\n        padded_tokens = jnp.pad(tokens, ((0, 0), (0, seqlen - current_len)), \"constant\")\n\n        print(tokenizer.decode(tokens[0]), end=\"\", flush=True)\n\n        for i in range(max_tokens):\n            key, subkey = jax.random.split(key)\n\n            next_token = self.generate_step_static(\n                params, static_def, padded_tokens, current_len, subkey\n            )\n\n            if next_token.item() == end_token:\n                break\n\n            print(tokenizer.decode([next_token.item()]), end=\"\", flush=True)\n\n            padded_tokens = padded_tokens.at[:, current_len].set(next_token.item())\n            current_len += 1\n\n        final_tokens = padded_tokens[0, :current_len]\n        return tokenizer.decode(final_tokens.tolist())\n\n\ndef create_model(rngs):\n    return GPT2(\n        seqlen,\n        vocab_size,\n        embed_dim,\n        num_heads,\n        dropout_rate,\n        feed_forward_dim,\n        num_transformer_blocks,\n        rngs=rngs,\n    )","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:51.030093Z","iopub.execute_input":"2025-07-16T08:10:51.030351Z","iopub.status.idle":"2025-07-16T08:10:51.070930Z","shell.execute_reply.started":"2025-07-16T08:10:51.030328Z","shell.execute_reply":"2025-07-16T08:10:51.065052Z"},"id":"z0p-IHurrB9i","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Use Weights and Biases to track training progress.","metadata":{"id":"eBfT1dp5hMUm"}},{"cell_type":"code","source":"if platform == \"Colab\":\n  from google.colab import userdata\n  os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')\n  os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n  os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\nelif platform == \"Kaggle\":\n  from kaggle_secrets import UserSecretsClient\n  user_secrets = UserSecretsClient()\n  os.environ['WANDB_API_KEY'] = user_secrets.get_secret('WANDB_API_KEY')\nelse:\n  print(\"Please set the WANDB_API_KEY env variable manually\") #input()\n\nwandb.login()\n\nimport wandb\n\nwandb.init(\n    # set the wandb project where this run will be logged\n    project='GPT2-DPO',\n\n    # track hyperparameters and run metadata\n    config={\n      'architecture': GPT2_variant,\n      'dataset': 'OpenWebText',\n      'platform': platform,\n      'dtype': dtype,\n      'param_dtype': param_dtype,\n      'init_learning_rate': init_learning_rate,\n      'num_transformer_blocks': num_transformer_blocks,\n      'seqlen': seqlen,\n      'embed_dim': embed_dim,\n      'num_heads': num_heads,\n      'feed_forward_dim': feed_forward_dim,\n      'max_steps': 'unknown',\n      'batch_size': batch_size,\n      'weight_decay': weight_decay,\n      'beta': beta\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2025-07-16T08:10:51.072738Z","iopub.execute_input":"2025-07-16T08:10:51.072961Z","iopub.status.idle":"2025-07-16T08:10:53.678568Z","shell.execute_reply.started":"2025-07-16T08:10:51.072941Z","shell.execute_reply":"2025-07-16T08:10:53.674014Z"},"id":"IbhEtsganEWg","trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwindmaple\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250716_081052-6t1l9cnj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/windmaple/GPT2-DPO/runs/6t1l9cnj' target=\"_blank\">stoic-feather-15</a></strong> to <a href='https://wandb.ai/windmaple/GPT2-DPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/windmaple/GPT2-DPO' target=\"_blank\">https://wandb.ai/windmaple/GPT2-DPO</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/windmaple/GPT2-DPO/runs/6t1l9cnj' target=\"_blank\">https://wandb.ai/windmaple/GPT2-DPO/runs/6t1l9cnj</a>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/windmaple/GPT2-DPO/runs/6t1l9cnj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fb3746f8430>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## DPO\n\nDPO training requires a model to be trained and a separate reference model to compute loss. We are going to initialize them from our previous instruct tuned 124M GPT2 model. On Kaggle, you need to manually add the [model](https://www.kaggle.com/models/windmaple/gpt2/jax/124m-it) as input.","metadata":{"id":"mI1ci-HyMspJ"}},{"cell_type":"code","source":"import orbax.checkpoint as orbax\nfrom orbax.checkpoint import PyTreeCheckpointer\nimport numpy as np\nfrom datasets import load_dataset\n\n# Create the model and load the pretrained weights\nmodel = create_model(rngs=nnx.Rngs(0))\nstate = nnx.state(model)\ncheckpointer = PyTreeCheckpointer()\n\ncheckpoint_path = '/kaggle/input/gpt2/jax/124m-it/1'\nstate = checkpointer.restore(checkpoint_path, item=state)\nnnx.update(model, state)\n\n# Create a reference model with the same pretrained weights\nref_model = create_model(rngs=nnx.Rngs(1))\nref_state = nnx.state(ref_model)\nref_state = checkpointer.restore(checkpoint_path, item=ref_state)\nnnx.update(ref_model, ref_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:10:53.681342Z","iopub.execute_input":"2025-07-16T08:10:53.681595Z","iopub.status.idle":"2025-07-16T08:11:00.982557Z","shell.execute_reply.started":"2025-07-16T08:10:53.681569Z","shell.execute_reply":"2025-07-16T08:11:00.976518Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/orbax/checkpoint/_src/serialization/type_handlers.py:1251: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"We are going to use a [pairwise preference dataset from Argilla](https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences-cleaned). And create a preprocessing helper function and a dataloader.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nds = load_dataset(\n    \"argilla/ultrafeedback-binarized-preferences-cleaned\", split=\"train\"\n)\n\nmax_steps = ds.num_rows // batch_size\n\n# Define the template for the chat messages\ntemplate = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n{output}\"\n\n# Define a helper function to preprocess the dataset\ndef preprocess_function(examples):\n    def format_and_tokenize(messages):\n        prompts = []\n        for msg_pair in messages:\n            instruction = msg_pair[0][\"content\"]\n            output = msg_pair[1][\"content\"] if len(msg_pair) > 1 else \"\"\n            prompts.append(\n                template.format(instruction=instruction, input=\"\", output=output)\n            )\n\n        tokenized_prompts = [tokenizer.encode(p) for p in prompts]\n\n        input_ids = []\n        attention_masks = []\n\n        for tokens in tokenized_prompts:\n            if len(tokens) > seqlen:\n                tokens = tokens[:seqlen]\n\n            padding_len = seqlen - len(tokens)\n            input_ids.append(tokens + [50256] * padding_len)\n            attention_masks.append([1] * len(tokens) + [0] * padding_len)\n\n        return np.array(input_ids), np.array(attention_masks)\n\n    chosen_input_ids, chosen_attention_mask = format_and_tokenize(examples[\"chosen\"])\n    rejected_input_ids, rejected_attention_mask = format_and_tokenize(\n        examples[\"rejected\"]\n    )\n\n    return {\n        \"chosen_input_ids\": chosen_input_ids,\n        \"chosen_attention_mask\": chosen_attention_mask,\n        \"rejected_input_ids\": rejected_input_ids,\n        \"rejected_attention_mask\": rejected_attention_mask,\n    }\n\n# Create a data loader.\ndef data_loader(dataset, batch_size):\n    while True:\n        for i in range(0, len(dataset[\"chosen\"]), batch_size):\n            batch = {\n                \"chosen\": dataset[\"chosen\"][i : i + batch_size],\n                \"rejected\": dataset[\"rejected\"][i : i + batch_size],\n            }\n            processed_batch = preprocess_function(batch)\n            yield processed_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:11:01.077665Z","iopub.execute_input":"2025-07-16T08:11:01.078309Z","iopub.status.idle":"2025-07-16T08:11:02.353937Z","shell.execute_reply.started":"2025-07-16T08:11:01.078271Z","shell.execute_reply":"2025-07-16T08:11:02.346512Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Now we can define functions to calculate DPO loss.","metadata":{}},{"cell_type":"code","source":"# Define the DPO loss function\ndef dpo_loss(\n    policy_chosen_logps,\n    policy_rejected_logps,\n    ref_chosen_logps,\n    ref_rejected_logps,\n    beta,\n):\n    pi_logratios = policy_chosen_logps - policy_rejected_logps\n    ref_logratios = ref_chosen_logps - ref_rejected_logps\n    return -jax.nn.log_sigmoid(beta * (pi_logratios - ref_logratios))\n\n\n# Define a function to get the log probabilities of the sequences\ndef get_log_probs(logits, labels, attention_mask):\n    batch_size, seq_len = labels.shape\n    assert logits.shape[:2] == (batch_size, seq_len), f\"Shape mismatch: {logits.shape} vs {labels.shape}\"\n\n    # Get the log probabilities from the logits.\n    log_probs = jax.nn.log_softmax(logits, axis=-1)\n    # Get the log probabilities of the labels.\n    log_probs_labels = jnp.squeeze(\n        jnp.take_along_axis(log_probs, labels[:, :, None], axis=-1), -1\n    )\n    # Set the log probabilities of the padding tokens to 0.\n    return (log_probs_labels * attention_mask).sum(axis=-1)\n\n\ndef calculate_loss(model, ref_model, batch, rngs):\n    # Get the logits from the policy model.\n    policy_chosen_logits = model(batch[\"chosen_input_ids\"], training=True, rngs=rngs)\n    policy_rejected_logits = model(\n        batch[\"rejected_input_ids\"], training=True, rngs=rngs\n    )\n\n    # Get the log probabilities from the policy model.\n    policy_chosen_logps = get_log_probs(\n        policy_chosen_logits,\n        batch[\"chosen_input_ids\"],\n        batch[\"chosen_attention_mask\"],\n    )\n    policy_rejected_logps = get_log_probs(\n        policy_rejected_logits,\n        batch[\"rejected_input_ids\"],\n        batch[\"rejected_attention_mask\"],\n    )\n\n    # Get the logits from the reference model.\n    ref_chosen_logits = jax.lax.stop_gradient(ref_model(batch[\"chosen_input_ids\"], training=False))\n    ref_rejected_logits = jax.lax.stop_gradient(ref_model(batch[\"rejected_input_ids\"], training=False))\n\n    # Get the log probabilities from the reference model.\n    ref_chosen_logps = get_log_probs(\n        ref_chosen_logits,\n        batch[\"chosen_input_ids\"],\n        batch[\"chosen_attention_mask\"],\n    )\n    ref_rejected_logps = get_log_probs(\n        ref_rejected_logits,\n        batch[\"rejected_input_ids\"],\n        batch[\"rejected_attention_mask\"],\n    )\n\n    # Calculate the DPO loss.\n    loss = dpo_loss(\n        policy_chosen_logps,\n        policy_rejected_logps,\n        ref_chosen_logps,\n        ref_rejected_logps,\n        beta,\n    )\n    return jnp.mean(loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:11:02.358721Z","iopub.execute_input":"2025-07-16T08:11:02.359180Z","iopub.status.idle":"2025-07-16T08:11:02.376609Z","shell.execute_reply.started":"2025-07-16T08:11:02.359154Z","shell.execute_reply":"2025-07-16T08:11:02.372076Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Now we run the finetuning.","metadata":{}},{"cell_type":"code","source":"start_prompt = template.format(\n    instruction=\"What is the future for human?\",\n    input=\"\",\n    output=\"\",\n)\nstart_tokens = tokenizer.encode(start_prompt)[:seqlen]\nprint(f\"***Generated text before DPO:\")\ngenerated_text = model.generate_text(seqlen // 5, start_tokens)\n\n# Define the training step\n@nnx.jit\ndef train_step(model, optimizer, ref_model, batch, rngs):\n    # Calculate the loss and gradients with respect to the model's parameters.\n    loss, grads = nnx.value_and_grad(calculate_loss, argnums=0)(\n        model, ref_model, batch, rngs\n    )\n    # Update the model's parameters.\n    optimizer.update(grads)\n    return loss\n\noptimizer = nnx.Optimizer(\n    model, \n    optax.chain(\n        optax.clip_by_global_norm(1.0),  # Add gradient clipping\n        optax.adamw(learning_rate=init_learning_rate, weight_decay=weight_decay)\n    )\n)\n\ndata_gen = data_loader(ds, batch_size)\nrngs = nnx.Rngs(0)\n\n# Train the model\nfor step in range(max_steps):\n    batch = next(data_gen)\n    batch = jax.device_put(batch, NamedSharding(mesh, P(\"batch\")))\n    loss = train_step(model, optimizer, ref_model, batch, rngs=rngs)\n    if step % 50 == 0:\n        print(f\"Step {step}, Loss: {loss}\")        \n        wandb.log(data={'Loss': loss}, step=step)\n\n# Generate text after DPO\nprint(f\"***Generated text after DPO:\")\ngenerated_text = model.generate_text(seqlen // 5, start_tokens)\n","metadata":{"id":"6uHcKfOvbcsx","colab":{"base_uri":"https://localhost:8080/","height":480},"outputId":"9f2885b7-3cfb-4562-d54a-6bca1c651215","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:11:02.381562Z","iopub.execute_input":"2025-07-16T08:11:02.381802Z","iopub.status.idle":"2025-07-16T08:38:29.574778Z","shell.execute_reply.started":"2025-07-16T08:11:02.381779Z","shell.execute_reply":"2025-07-16T08:38:29.569394Z"}},"outputs":[{"name":"stdout","text":"***Generated text before DPO:\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nWhat is the future for human?\n\n### Input:\n\n\n### Response:\nAs human beings progress to their next evolutionary stages on a much larger and more advanced level and become even faster-Evolutron. In the next evolutionary stage they will be able to survive for billions of years and will become a species with a special form. Their genetic material is made up of cells that have unique features such as wings, hair, and a single organelle within the wings of a human. The cells will eventually have evolved over time, and their genetic structure and function has been modified drastically as human evolution takes a far more complex journey.Step 0, Loss: 5.59375\nStep 50, Loss: 2.59375\nStep 100, Loss: 2.09375\nStep 150, Loss: 1.10156\nStep 200, Loss: 2.0625\nStep 250, Loss: 1.96094\nStep 300, Loss: 2.07812\nStep 350, Loss: 2.07812\nStep 400, Loss: 1.9375\nStep 450, Loss: 1.125\nStep 500, Loss: 1.75781\nStep 550, Loss: 1.36719\nStep 600, Loss: 1.15625\nStep 650, Loss: 1.5625\nStep 700, Loss: 1.41406\nStep 750, Loss: 1.71094\nStep 800, Loss: 1.35938\nStep 850, Loss: 0.84375\nStep 900, Loss: 0.882812\nStep 950, Loss: 1.02344\n***Generated text after DPO:\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nWhat is the future for human?\n\n### Input:\n\n\n### Response:\nThe future for humans may include an increase in AI-led development initiatives, improved medical technology, improved communication and collaboration technologies, or improved transportation technologies. In the short term, advances in automation may lead to advances in artificial technologies such as AI and Machine Learning technology. However, human labor is becoming more important in many fields as machines can be used by machines for tasks with humans to perform repetitive tasks. Additionally, advances in technology could help in increasing the efficiency of tasks and making tasks simpler.","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"id":"ANTHzx4TrzTE","trusted":true},"outputs":[],"execution_count":null}]}